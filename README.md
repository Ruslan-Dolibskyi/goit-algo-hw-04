### goit-algo-hw-04
# Висновки:

Ця таблиця наглядно демонструє, як швидкість кожного з алгоритмів сортування змінюється залежно від розміру набору даних.
| Алгоритм сортування   | Small (100 елементів) | Medium (1000 елементів) | Large (10000 елементів) |
|-----------------------|-----------------------|-------------------------|-------------------------|
| Insertion Sort        | 0.0132 секунди        | 0.4222 секунди          | 19.7642 секунди         |
| Merge Sort            | 0.0367 секунди        | 0.0138 секунди          | 0.2211 секунди          |
| Tim sort              | 0.00002368 секунди    | 0.0001835 секунди       | 0.001856 секунди        |

***Сортування вставками*** є досить швидким на малих наборах даних, але його ефективність значно знижується зі зростанням розміру даних. Це пов'язано з квадратичною часовою складністю алгоритму O(n2).

***Сортування злиттям*** показує кращу продуктивність, особливо на середніх та великих наборах даних, завдяки його часовій складності O(n log n).

***Timsort***, гібридний алгоритм, що використовує переваги обох попередніх алгоритмів, показує найкращу продуктивність у всіх сценаріях. Це підтверджує, чому Python використовує Timsort як алгоритм за замовчуванням для сортування — він ефективний для різних розмірів та типів даних.

Емпіричні дані підтверджують теоретичні оцінки складності цих алгоритмів. Timsort виявився значно ефективнішим у порівнянні з чистими алгоритмами сортування вставками та злиттям, забезпечуючи високу ефективність як на малих, так і на великих наборах даних. Це підкреслює, чому в більшості випадків програмісти воліють використовувати вбудовані в Python алгоритми сортування, замість того щоб кодувати свої власні.